'''
Minimal code to implement temporal cluster tomography.

A version of this code was used for parts of the analysis in the paper "Spatial and Temporal
Cluster Tomography of Active Matter", by L.V.Luzzatto, M. Casiulis, S. Martiniani, & I.A. Kov√°cs,
available as an e-print at https://arxiv.org/abs/2511.09444.

Requires data generated with 'cluster_membership.py' 

NOTE:   some functions had to be jitted (using NUMBA) to run the code on the full dataset used in
        the paper. Some of the specified data types (e.g. int64, uint32, etc.) might have to be
        modified to suit the larger/smaller number of particles in a different dataset.

Leone Luzzatto - created: 2025.01.14; final version: 2025.11.30.
'''

import numpy as np
import pickle
from math import comb
from numba import njit
from collections import Counter
from time import perf_counter

###########################################
# FUNCTIONS

#__________________________________________
'''
get_cluster_list(cluster_data)
Reconstruct cluster membership from files generated by 'cluster_membership.py'.

Input:
    - (array) cluster membership data from the output of 'cluster_membership.py'
    - (int) number of particles to be used in the analysis

Return:
    - list of particles IDs in each cluster
'''
def get_cluster_list(cluster_data, n_particles):
    cluster_list = [[]]
    for i in cluster_data[:]:
        if i == -1 :
            cluster_list.append([])
        elif i < n_particles:
            cluster_list[-1].append(i)
        else:
            continue
    
    return cluster_list


#__________________________________________
'''
get_cluster_signal(cluster, n_particles, n_pairs)
From a list of particles belonging to a cluster, construct a boolean array marking which
particle pairs are found within the cluster.

Input:
    - (array) list of particles from the sample found in a cluster
    - total number of particles in the sample
    - total number of particle pairs

Return:
    - boolean array marking whether any given pair is found within the cluster
'''
@njit("boolean[:](uint32[:], uint64, uint64)")
def get_cluster_signal(cluster, n_particles, n_pairs):
    N = len(cluster)
    cluster_signal = np.array([False]*n_pairs)

    for i in range(N):
        p1 = cluster[i]
        for j in range(i+1,N):
            p2 = cluster[j]
            idx = (p2 - 1 + (n_particles - 1)*p1 - (p1*(p1+1))//2) # unique ID of the pair (p1,p2)
            cluster_signal[idx] = True
    
    return cluster_signal


#__________________________________________
'''
get_pairs_signal(clusters, n_particles, n_pairs)
Given the full list of clusters, identify which pairs of particles within the
sample are in the same cluster.

Input:
    - (array) list of clusters
    - total number of particles in the sample
    - total number of particle pairs

Return:
    - boolean array marking whether any given pair is found in the same cluster,
        considering all clusters
'''
def get_pairs_signal(clusters, n_particles, n_pairs):
    signal = np.zeros([n_pairs,], dtype=np.bool_)
    
    # compute the signal due to the remaining clusters
    for cluster in clusters:
        cluster = np.array(cluster, dtype=np.uint32)
        cluster_signal = get_cluster_signal(cluster, n_particles, n_pairs)
        signal += cluster_signal
            
    return signal


##########################################################################################################
# ANALYSIS

t_start = perf_counter()

# Set variables
size = 64
Pe_r = 100
phi = 0.26
n_timesteps = 100 # max number of snapshots to be used
skip = 0 # number of snapshot to skip to account for burn-in
n_particles = int( size**2 * 4/np.pi * phi ) # number of particles used in the analysis
n_pairs = comb(n_particles, 2)

# Set up input and output files
from pathlib import Path
in_dir = './'
out_dir = './'
Path(out_dir).mkdir(parents=True, exist_ok=True)

# arrays needed for the analysis
temporal_gapsize = np.zeros([n_timesteps,], dtype=np.uint64) # temporal gap-size statistics
seen = np.zeros([n_pairs,], dtype=np.bool_) # whether any given pair has been observed in the same cluster or not
last_seen = np.zeros([n_pairs,], dtype=np.uint32) # last time a pair was in the same cluster
pair_ids = np.arange(n_pairs, dtype=np.uint64) # unique ID number for each pair

# Analyze the data
with open(in_dir + 'clusters.out', 'rb') as data_file:
    data = pickle.load(data_file)

t_tot = min(len(data), n_timesteps)
seen_all = False
for t, snapshot in enumerate(data[skip:t_tot]): # '+1' because the first row of 'data' is a header
    cluster_list = get_cluster_list(snapshot, n_particles)
    signal = get_pairs_signal(cluster_list, n_particles, n_pairs)        
        
    if not seen_all: # ensures that we only consider gaps that are fully within the time window
        
        # save the time-step at which a pair is first seen in the same cluster
        last_seen[np.logical_and(signal, np.logical_not(seen))] = t
        
        # keep only pairs that are in the same cluster at time-step t
        # AND have already been in the same cluster at least once
        seen, signal = np.logical_or(seen, signal), np.logical_and(seen, signal)
        seen_all = np.all(seen)        

    # for all pairs in the same cluster at time-step t, check the last
    # time they were in the same cluster, then save the corresponding
    # temporal gaps and update the record of the last time they were
    # seen in the same cluster. 
    # on_pair_ids = pair_ids[signal]
    gaps = t - last_seen[signal]
    for s, n in Counter(gaps).items():
        temporal_gapsize[s] += n
    last_seen[signal] = t

temporal_gapsize = temporal_gapsize / (t_tot * n_pairs)
   
# Write results to .txt files
with open(out_dir + 'temporal_gapsize.txt', 'wb') as outfile: 
    np.savetxt(outfile, temporal_gapsize, header='Temporal gap-size statistics, n_t(s_t)', delimiter='\n') 

##########################################################################################################
# END

t_stop = perf_counter()
print('Temporal cluster tomography')
print('L = {}; Pe_r = {}; phi = {:.3f}; N = {}; {} snapshots'.format(size, Pe_r, phi, n_particles, t_tot-skip))
print('Results saved ({:.2f} seconds).'.format(t_stop-t_start))
